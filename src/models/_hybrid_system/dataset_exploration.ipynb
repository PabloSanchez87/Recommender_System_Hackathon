{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths dataset + carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/products_data.pkl'\n",
    "user_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/user_data.csv'\n",
    "test_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/test_data.pkl'\n",
    "train_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/train_data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datasets\n",
    "products = pd.read_pickle(product_path)\n",
    "users = pd.read_csv(user_path)\n",
    "test = pd.read_pickle(test_path)\n",
    "train = pd.read_pickle(train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploración del dataset: Products\n",
      "Forma: (43692, 6)\n",
      "Primeras filas:\n",
      "   discount                                          embedding  partnumber  \\\n",
      "0         0  [-0.13401361, -0.1200429, -0.016117405, -0.167...       32776   \n",
      "1         0  [-0.0949274, -0.107294075, -0.16559914, -0.174...       41431   \n",
      "2         0  [-0.12904441, -0.07724628, -0.09799071, -0.164...       39419   \n",
      "3         1  [-0.12783332, -0.133868, -0.10101265, -0.18888...       36087   \n",
      "4         1  [-0.14092924, -0.1258284, -0.10809927, -0.1765...       34132   \n",
      "\n",
      "   color_id  cod_section  family  \n",
      "0        85            4      73  \n",
      "1       135            4      73  \n",
      "2       339            4      73  \n",
      "3       135            4      73  \n",
      "4         3            4      73  \n",
      "\n",
      "Tipos de datos:\n",
      "discount         int8\n",
      "embedding      object\n",
      "partnumber      int32\n",
      "color_id        int32\n",
      "cod_section     int16\n",
      "family          int32\n",
      "dtype: object\n",
      "\n",
      "Valores faltantes:\n",
      "discount       0\n",
      "embedding      0\n",
      "partnumber     0\n",
      "color_id       0\n",
      "cod_section    0\n",
      "family         0\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "Exploración del dataset: Users\n",
      "Forma: (557006, 5)\n",
      "Primeras filas:\n",
      "   user_id  country         R         F         M\n",
      "0   430096       25  0.016438  0.000558  0.000001\n",
      "1   134018       25  0.060274  0.002976  0.000003\n",
      "2    53750       25  0.001826  0.005951  0.000003\n",
      "3   180665       25  0.020091  0.002046  0.000003\n",
      "4   134209       25  0.006393  0.000186  0.000003\n",
      "\n",
      "Tipos de datos:\n",
      "user_id      int64\n",
      "country      int64\n",
      "R          float64\n",
      "F          float64\n",
      "M          float64\n",
      "dtype: object\n",
      "\n",
      "Valores faltantes:\n",
      "user_id    0\n",
      "country    0\n",
      "R          0\n",
      "F          0\n",
      "M          0\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "Exploración del dataset: Test\n",
      "Forma: (29275, 8)\n",
      "Primeras filas:\n",
      "   session_id       date         timestamp_local  user_id  country  \\\n",
      "0         746 2024-06-15 2024-06-15 18:36:47.390       -1       57   \n",
      "1         746 2024-06-15 2024-06-15 18:37:04.052       -1       57   \n",
      "2         746 2024-06-15 2024-06-15 18:37:48.159       -1       57   \n",
      "3         746 2024-06-15 2024-06-15 18:38:19.899       -1       57   \n",
      "4         746 2024-06-15 2024-06-15 18:38:46.492       -1       57   \n",
      "\n",
      "   partnumber  device_type  pagetype  \n",
      "0        1254            1        24  \n",
      "1       32544            1        24  \n",
      "2       12639            1        24  \n",
      "3       18048            1        24  \n",
      "4       13295            1        24  \n",
      "\n",
      "Tipos de datos:\n",
      "session_id                  int32\n",
      "date               datetime64[ns]\n",
      "timestamp_local    datetime64[ns]\n",
      "user_id                     int32\n",
      "country                     int16\n",
      "partnumber                  int32\n",
      "device_type                  int8\n",
      "pagetype                    int16\n",
      "dtype: object\n",
      "\n",
      "Valores faltantes:\n",
      "session_id         0\n",
      "date               0\n",
      "timestamp_local    0\n",
      "user_id            0\n",
      "country            0\n",
      "partnumber         0\n",
      "device_type        0\n",
      "pagetype           0\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "Exploración del dataset: Train\n",
      "Forma: (46551445, 9)\n",
      "Primeras filas:\n",
      "   session_id       date         timestamp_local  add_to_cart  user_id  \\\n",
      "0          64 2024-06-06 2024-06-06 16:43:17.389            0       -1   \n",
      "1         117 2024-06-08 2024-06-08 15:11:02.782            0       -1   \n",
      "2         117 2024-06-08 2024-06-08 15:11:44.797            0       -1   \n",
      "3         579 2024-06-05 2024-06-05 19:24:48.397            0       -1   \n",
      "4        1220 2024-06-04 2024-06-04 08:21:13.476            0   480729   \n",
      "\n",
      "   country  partnumber  device_type  pagetype  \n",
      "0       29       14327            1        24  \n",
      "1       57       38422            1        24  \n",
      "2       57       19763            1        24  \n",
      "3       29       30253            1        24  \n",
      "4       25        1592            1        24  \n",
      "\n",
      "Tipos de datos:\n",
      "session_id                  int32\n",
      "date               datetime64[ns]\n",
      "timestamp_local    datetime64[ns]\n",
      "add_to_cart                  int8\n",
      "user_id                     int32\n",
      "country                     int16\n",
      "partnumber                  int32\n",
      "device_type                  int8\n",
      "pagetype                    int16\n",
      "dtype: object\n",
      "\n",
      "Valores faltantes:\n",
      "session_id         0\n",
      "date               0\n",
      "timestamp_local    0\n",
      "add_to_cart        0\n",
      "user_id            0\n",
      "country            0\n",
      "partnumber         0\n",
      "device_type        0\n",
      "pagetype           0\n",
      "dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Exploración básica\n",
    "def explore_dataset(dataset, name):\n",
    "    print(f\"Exploración del dataset: {name}\")\n",
    "    print(f\"Forma: {dataset.shape}\")\n",
    "    print(\"Primeras filas:\")\n",
    "    print(dataset.head())\n",
    "    print(\"\\nTipos de datos:\")\n",
    "    print(dataset.dtypes)\n",
    "    print(\"\\nValores faltantes:\")\n",
    "    print(dataset.isnull().sum())\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Llamar a la función para cada dataset\n",
    "explore_dataset(products, \"Products\")\n",
    "explore_dataset(users, \"Users\")\n",
    "explore_dataset(test, \"Test\")\n",
    "explore_dataset(train, \"Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Tratamiento de usuarios no logueados\n",
    "`Objetivo`: Confirmar que los valores -1 en user_id se interpreten correctamente como \"no logueados\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en user_id (Train): [    -1 480729 389707 350824  51325] ...\n",
      "Valores únicos en user_id (Test): [    -1 259465 486272 217706 143895] ...\n",
      "Usuarios no logueados en Train: 39694715\n",
      "Usuarios no logueados en Test: 23509\n"
     ]
    }
   ],
   "source": [
    "# Revisar valores únicos de user_id en Train y Test\n",
    "print(\"Valores únicos en user_id (Train):\", train['user_id'].unique()[:5], \"...\")\n",
    "print(\"Valores únicos en user_id (Test):\", test['user_id'].unique()[:5], \"...\")\n",
    "\n",
    "# Comprobar cantidad de usuarios no logueados\n",
    "print(\"Usuarios no logueados en Train:\", (train['user_id'] == -1).sum())\n",
    "print(\"Usuarios no logueados en Test:\", (test['user_id'] == -1).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Verificar consistencia entre Train y Test\n",
    "`Objetivo 1:` Asegurar que las columnas clave (user_id, session_id, partnumber) tienen el mismo tipo de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos Train:\n",
      "session_id                  int32\n",
      "date               datetime64[ns]\n",
      "timestamp_local    datetime64[ns]\n",
      "add_to_cart                  int8\n",
      "user_id                     int32\n",
      "country                     int16\n",
      "partnumber                  int32\n",
      "device_type                  int8\n",
      "pagetype                    int16\n",
      "dtype: object\n",
      "\n",
      "Tipos de datos Test:\n",
      "session_id                  int32\n",
      "date               datetime64[ns]\n",
      "timestamp_local    datetime64[ns]\n",
      "user_id                     int32\n",
      "country                     int16\n",
      "partnumber                  int32\n",
      "device_type                  int8\n",
      "pagetype                    int16\n",
      "dtype: object\n",
      "Tipos de datos consistentes entre Train y Test.\n"
     ]
    }
   ],
   "source": [
    "# Verificar tipos de datos\n",
    "print(\"Tipos de datos Train:\")\n",
    "print(train.dtypes)\n",
    "print(\"\\nTipos de datos Test:\")\n",
    "print(test.dtypes)\n",
    "\n",
    "# Comprobar si los tipos coinciden entre Train y Test\n",
    "assert train['user_id'].dtype == test['user_id'].dtype, \"Tipo de user_id inconsistente\"\n",
    "assert train['session_id'].dtype == test['session_id'].dtype, \"Tipo de session_id inconsistente\"\n",
    "assert train['partnumber'].dtype == test['partnumber'].dtype, \"Tipo de partnumber inconsistente\"\n",
    "print(\"Tipos de datos consistentes entre Train y Test.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Objetivo 2`: Revisar si los partnumber en Test están presentes en Products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partnumbers en Test no presentes en Products: 0\n"
     ]
    }
   ],
   "source": [
    "# Verificar si todos los partnumber de Test están en Products\n",
    "test_partnumbers = test['partnumber'].unique()\n",
    "products_partnumbers = products['partnumber'].unique()\n",
    "\n",
    "missing_partnumbers = set(test_partnumbers) - set(products_partnumbers)\n",
    "print(f\"Partnumbers en Test no presentes en Products: {len(missing_partnumbers)}\")\n",
    "if len(missing_partnumbers) > 0:\n",
    "    print(\"Ejemplo de Partnumbers faltantes:\", list(missing_partnumbers)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Validar unicidad\n",
    "`Objetivo:` Confirmar que los identificadores son únicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados en session_id (Train): 41977689\n",
      "Duplicados en session_id (Test): 21926\n",
      "Duplicados en partnumber (Products): 0\n"
     ]
    }
   ],
   "source": [
    "# Comprobar unicidad de identificadores clave\n",
    "print(\"Duplicados en session_id (Train):\", train.duplicated(subset=['session_id']).sum())\n",
    "print(\"Duplicados en session_id (Test):\", test.duplicated(subset=['session_id']).sum())\n",
    "\n",
    "print(\"Duplicados en partnumber (Products):\", products.duplicated(subset=['partnumber']).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Asegurar alineación con el enfoque\n",
    "`Colaborativo:` Revisar densidad de interacciones user_id vs. partnumber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de densidad de interacciones por usuario:\n",
      "count    3.800530e+05\n",
      "mean     1.224867e+02\n",
      "std      6.438882e+04\n",
      "min      1.000000e+00\n",
      "25%      3.000000e+00\n",
      "50%      7.000000e+00\n",
      "75%      1.900000e+01\n",
      "max      3.969472e+07\n",
      "Name: partnumber, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Comprobar número de interacciones por usuario\n",
    "interaction_density = train.groupby('user_id')['partnumber'].count()\n",
    "print(\"Resumen de densidad de interacciones por usuario:\")\n",
    "print(interaction_density.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Contenido:` Validar si los embeddings están normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de normalización de embeddings:\n",
      "count    43692.000000\n",
      "mean        10.518237\n",
      "std          2.610645\n",
      "min          4.942136\n",
      "25%          9.917526\n",
      "50%         11.005746\n",
      "75%         12.059213\n",
      "max         19.455055\n",
      "Name: embedding, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Verificar normalización de embeddings en Products\n",
    "import numpy as np\n",
    "\n",
    "embeddings = products['embedding'].apply(lambda x: np.array(x))\n",
    "norms = embeddings.apply(np.linalg.norm)\n",
    "print(\"Estadísticas de normalización de embeddings:\")\n",
    "print(norms.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Popularidad:` Validar tendencias útiles en add_to_cart y pagetype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de add_to_cart:\n",
      "add_to_cart\n",
      "0    0.941016\n",
      "1    0.058984\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribución de pagetype:\n",
      "pagetype\n",
      " 24    9.936603e-01\n",
      " 8     2.784876e-03\n",
      " 6     2.437969e-03\n",
      " 19    4.196218e-04\n",
      " 16    3.299361e-04\n",
      " 7     1.709721e-04\n",
      " 1     7.845084e-05\n",
      " 17    4.876326e-05\n",
      "-1     2.571349e-05\n",
      " 25    8.957831e-06\n",
      " 23    6.337075e-06\n",
      " 20    6.014851e-06\n",
      " 10    5.069660e-06\n",
      " 3     4.124469e-06\n",
      " 5     3.544466e-06\n",
      " 21    2.942981e-06\n",
      " 12    1.353341e-06\n",
      " 13    1.160007e-06\n",
      " 26    1.052599e-06\n",
      " 14    7.088931e-07\n",
      " 9     6.014851e-07\n",
      " 11    5.800035e-07\n",
      " 22    2.792609e-07\n",
      " 15    2.148161e-07\n",
      " 2     1.074081e-07\n",
      " 34    4.296322e-08\n",
      " 31    4.296322e-08\n",
      " 30    2.148161e-08\n",
      " 18    2.148161e-08\n",
      " 4     2.148161e-08\n",
      " 32    2.148161e-08\n",
      " 29    2.148161e-08\n",
      " 37    2.148161e-08\n",
      " 27    2.148161e-08\n",
      " 33    2.148161e-08\n",
      " 35    2.148161e-08\n",
      " 36    2.148161e-08\n",
      " 28    2.148161e-08\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analizar distribución de add_to_cart y pagetype\n",
    "print(\"Distribución de add_to_cart:\")\n",
    "print(train['add_to_cart'].value_counts(normalize=True))\n",
    "print(\"\\nDistribución de pagetype:\")\n",
    "print(train['pagetype'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustes sobre los datasets para que se alinen mejor a nuestro enfoque:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de duplicados en Train:\n",
      "    session_id       date         timestamp_local  add_to_cart  user_id  \\\n",
      "4         1220 2024-06-04 2024-06-04 08:21:13.476            0   480729   \n",
      "5         1220 2024-06-04 2024-06-04 08:21:09.139            0   480729   \n",
      "9         1222 2024-06-13 2024-06-13 06:17:57.411            0       -1   \n",
      "11        1222 2024-06-13 2024-06-13 06:19:09.272            1       -1   \n",
      "13        1222 2024-06-13 2024-06-13 06:19:18.028            0       -1   \n",
      "\n",
      "    country  partnumber  device_type  pagetype  \n",
      "4        25        1592            1        24  \n",
      "5        25        1592            1        24  \n",
      "9        57        5249            1        24  \n",
      "11       57        5249            1        24  \n",
      "13       57       21714            1        24  \n"
     ]
    }
   ],
   "source": [
    "# Filtrar duplicados en Train por session_id y partnumber\n",
    "duplicates = train[train.duplicated(subset=['session_id', 'partnumber'], keep=False)]\n",
    "print(\"Ejemplo de duplicados en Train:\")\n",
    "print(duplicates.head())\n",
    "\n",
    "# Analizar diferencias entre duplicados\n",
    "differences = duplicates.groupby(['session_id', 'partnumber']).nunique()\n",
    "print(\"Número de valores únicos por columna en duplicados:\")\n",
    "print(differences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Análisis de los Resultados de los ajustes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1. Duplicados en `Train`**\n",
    "**Observaciones**:\n",
    "- Los duplicados tienen valores idénticos en algunas columnas (`user_id`, `country`, `partnumber`, `device_type`, `pagetype`) pero difieren en:\n",
    "  - **`timestamp_local`**: Marca temporal diferente, indicando que son interacciones distintas en la misma sesión.\n",
    "  - **`add_to_cart`**: En un caso el producto fue añadido al carrito (`1`), en otro no (`0`).\n",
    "\n",
    "**Implicaciones**:\n",
    "- Estos datos duplicados no son redundantes; reflejan interacciones diferentes dentro de la misma sesión. Por ejemplo:\n",
    "  - Para `session_id = 1222`, hay dos interacciones con `partnumber = 5249` con diferentes acciones (`add_to_cart = 0` y `add_to_cart = 1`).\n",
    "  - Este tipo de duplicado es **información válida** y útil para capturar el comportamiento del usuario.\n",
    "\n",
    "**Recomendaciones**:\n",
    "1. **No eliminar duplicados directamente**: Eliminar duplicados puede significar pérdida de información sobre las acciones del usuario.\n",
    "2. **Manejar duplicados en función del modelo**:\n",
    "   - Si usamos modelos **basados en sesiones**, podemos priorizar la interacción más reciente (`timestamp_local`) o con mayor relevancia (`add_to_cart = 1`).\n",
    "   - Si usamos modelos **basados en todas las interacciones**, conservar todas las filas para capturar el comportamiento completo del usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del dataset después de priorizar interacciones relevantes: (36858893, 9)\n"
     ]
    }
   ],
   "source": [
    "# Priorizar filas con add_to_cart = 1 dentro de cada session_id y partnumber\n",
    "train = train.sort_values(by=['add_to_cart', 'timestamp_local'], ascending=[False, False])\n",
    "train = train.drop_duplicates(subset=['session_id', 'partnumber'], keep='first')\n",
    "\n",
    "print(f\"Forma del dataset después de priorizar interacciones relevantes: {train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalización completada. Ejemplo de embeddings normalizados:\n",
      "0    [-0.01306566409766674, -0.011703588999807835, ...\n",
      "1    [-0.009752826765179634, -0.011023376137018204,...\n",
      "2    [-0.012108728289604187, -0.00724831223487854, ...\n",
      "3    [-0.0129902558401227, -0.01360349077731371, -0...\n",
      "4    [-0.01368741039186716, -0.012220778502523899, ...\n",
      "Name: embedding, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Normalizar embeddings\n",
    "products['embedding'] = products['embedding'].apply(lambda x: (np.array(x) / np.linalg.norm(x)).tolist())\n",
    "print(\"Normalización completada. Ejemplo de embeddings normalizados:\")\n",
    "print(products['embedding'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sustituimos valores -1 de pagetype, device_type y country. (en RAW eran null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cambios realizados:\n",
      "         pagetype  device_type  country\n",
      "10725642       24            3       29\n",
      "35628113       24            1       34\n",
      "35628118       24            1       34\n",
      "9475628        24            3       34\n",
      "9475555        24            3       34\n"
     ]
    }
   ],
   "source": [
    "# Variables categóricas: Reemplazar -1 por 'missing'\n",
    "cols_categorical = ['pagetype', 'device_type']\n",
    "for col in cols_categorical:\n",
    "    train[col] = train[col].replace(-1, 'missing')\n",
    "    test[col] = test[col].replace(-1, 'missing')\n",
    "\n",
    "# Variables numéricas: Imputar valores faltantes\n",
    "train['country'] = train['country'].replace(-1, train['country'].mode()[0])\n",
    "test['country'] = test['country'].replace(-1, test['country'].mode()[0])\n",
    "\n",
    "# Confirmar cambios\n",
    "print(\"Cambios realizados:\")\n",
    "print(train[['pagetype', 'device_type', 'country']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muestreo para el entrenamiento - 1% inicialmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de la muestra de Train: (368589, 9)\n"
     ]
    }
   ],
   "source": [
    "# Muestreo de Train (1% del dataset para pruebas)\n",
    "train_sample = train.sample(frac=0.01, random_state=42)\n",
    "print(f\"Tamaño de la muestra de Train: {train_sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño esperado de la muestra: 368589 filas\n"
     ]
    }
   ],
   "source": [
    "# Confirmar el tamaño de la muestra\n",
    "print(f\"Tamaño esperado de la muestra: {len(train) * 0.01:.0f} filas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Explorar la muestra\n",
    "Revisar la distribución y características de la muestra para confirmar que representa adecuadamente el dataset completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         session_id                           date  \\\n",
      "count  3.685890e+05                         368589   \n",
      "mean   2.585259e+06  2024-06-07 07:01:04.667149568   \n",
      "min    1.000000e+01            2024-06-01 00:00:00   \n",
      "25%    1.290344e+06            2024-06-04 00:00:00   \n",
      "50%    2.583594e+06            2024-06-07 00:00:00   \n",
      "75%    3.879591e+06            2024-06-11 00:00:00   \n",
      "max    5.171732e+06            2024-06-15 00:00:00   \n",
      "std    1.494213e+06                            NaN   \n",
      "\n",
      "                     timestamp_local    add_to_cart        user_id  \\\n",
      "count                         368589  368589.000000  368589.000000   \n",
      "mean   2024-06-07 22:01:48.314542336       0.071741   41608.927404   \n",
      "min       2024-06-01 02:00:03.965000       0.000000      -1.000000   \n",
      "25%       2024-06-04 10:10:05.748000       0.000000      -1.000000   \n",
      "50%    2024-06-07 19:54:29.023000064       0.000000      -1.000000   \n",
      "75%       2024-06-11 08:20:13.328000       0.000000      -1.000000   \n",
      "max       2024-06-15 11:13:04.191000       1.000000  557005.000000   \n",
      "std                              NaN       0.258059  117268.685100   \n",
      "\n",
      "             country     partnumber    device_type       pagetype  \n",
      "count  368589.000000  368589.000000  368589.000000  368589.000000  \n",
      "mean       36.346994   21701.504434       1.147205      23.878917  \n",
      "min        25.000000       3.000000       1.000000      -1.000000  \n",
      "25%        29.000000   11031.000000       1.000000      24.000000  \n",
      "50%        29.000000   21639.000000       1.000000      24.000000  \n",
      "75%        57.000000   32409.000000       1.000000      24.000000  \n",
      "max        57.000000   43692.000000       3.000000      25.000000  \n",
      "std        12.421209   12477.753794       0.513053       1.416250  \n",
      "add_to_cart\n",
      "0    0.928259\n",
      "1    0.071741\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Exploración básica de la muestra\n",
    "print(train_sample.describe())\n",
    "print(train_sample['add_to_cart'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         session_id                           date  \\\n",
      "count  3.685890e+05                         368589   \n",
      "mean   2.585259e+06  2024-06-07 07:01:04.667149568   \n",
      "min    1.000000e+01            2024-06-01 00:00:00   \n",
      "25%    1.290344e+06            2024-06-04 00:00:00   \n",
      "50%    2.583594e+06            2024-06-07 00:00:00   \n",
      "75%    3.879591e+06            2024-06-11 00:00:00   \n",
      "max    5.171732e+06            2024-06-15 00:00:00   \n",
      "std    1.494213e+06                            NaN   \n",
      "\n",
      "                     timestamp_local    add_to_cart        user_id  \\\n",
      "count                         368589  368589.000000  368589.000000   \n",
      "mean   2024-06-07 22:01:48.314542336       0.071741   41608.927404   \n",
      "min       2024-06-01 02:00:03.965000       0.000000      -1.000000   \n",
      "25%       2024-06-04 10:10:05.748000       0.000000      -1.000000   \n",
      "50%    2024-06-07 19:54:29.023000064       0.000000      -1.000000   \n",
      "75%       2024-06-11 08:20:13.328000       0.000000      -1.000000   \n",
      "max       2024-06-15 11:13:04.191000       1.000000  557005.000000   \n",
      "std                              NaN       0.258059  117268.685100   \n",
      "\n",
      "             country     partnumber    device_type  \n",
      "count  368589.000000  368589.000000  368589.000000  \n",
      "mean       36.346994   21701.504434       1.147205  \n",
      "min        25.000000       3.000000       1.000000  \n",
      "25%        29.000000   11031.000000       1.000000  \n",
      "50%        29.000000   21639.000000       1.000000  \n",
      "75%        57.000000   32409.000000       1.000000  \n",
      "max        57.000000   43692.000000       3.000000  \n",
      "std        12.421209   12477.753794       0.513053  \n",
      "pagetype\n",
      "24         0.992336\n",
      "8          0.003522\n",
      "6          0.002960\n",
      "19         0.000461\n",
      "16         0.000334\n",
      "7          0.000174\n",
      "1          0.000109\n",
      "17         0.000033\n",
      "missing    0.000022\n",
      "25         0.000022\n",
      "23         0.000011\n",
      "10         0.000008\n",
      "5          0.000005\n",
      "12         0.000003\n",
      "14         0.000003\n",
      "Name: proportion, dtype: float64\n",
      "device_type\n",
      "1    0.921639\n",
      "3    0.068844\n",
      "2    0.009517\n",
      "Name: proportion, dtype: float64\n",
      "country\n",
      "29    0.293186\n",
      "57    0.253779\n",
      "34    0.228148\n",
      "25    0.224887\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Exploración de la muestra ajustada\n",
    "print(train_sample.describe())\n",
    "print(train_sample['pagetype'].value_counts(normalize=True))\n",
    "print(train_sample['device_type'].value_counts(normalize=True))\n",
    "print(train_sample['country'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir la muestra en conjuntos de entrenamiento y validación\n",
    "Preparar los datos para probar modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: (294871, 9)\n",
      "Tamaño del conjunto de validación: (73718, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir la muestra\n",
    "train_set, val_set = train_test_split(train_sample, test_size=0.2, random_state=42)\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {train_set.shape}\")\n",
    "print(f\"Tamaño del conjunto de validación: {val_set.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Distribución temporal**\n",
    "- **`date` y `timestamp_local`**:\n",
    "  - La distribución temporal sigue siendo consistente y cubre del **2024-06-01** al **2024-06-15**.\n",
    "  - **Media, percentiles y rango**: Indican una buena representación del rango temporal de interacciones.\n",
    "\n",
    "**Conclusión**: La muestra refleja adecuadamente las interacciones del período completo.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Variable `add_to_cart`**\n",
    "- **Proporción**:\n",
    "  - `0`: **92.8%**.\n",
    "  - `1`: **7.2%**.\n",
    "- La proporción es consistente con la muestra anterior, confirmando que los cambios no afectaron la representación del desbalance.\n",
    "\n",
    "**Conclusión**: El desbalance sigue presente y debe manejarse adecuadamente en el modelado.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Variables categóricas**\n",
    "##### **`pagetype`**\n",
    "- **Distribución**:\n",
    "  - Dominancia del valor `24` (**99.2%**), lo que indica que es la página más interactuada.\n",
    "  - La categoría `missing` representa solo el **0.0022%**, indicando un impacto mínimo en la distribución.\n",
    "  \n",
    "##### **`device_type`**\n",
    "- **Distribución**:\n",
    "  - `1` (probablemente móvil o escritorio) domina con **92.2%**.\n",
    "  - `3` y `2` representan una proporción menor pero significativa.\n",
    "\n",
    "**Conclusión**: \n",
    "- Ambas variables tienen distribuciones consistentes, y la categoría `missing` no afecta significativamente el equilibrio.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Variable numérica `country`**\n",
    "- **Distribución**:\n",
    "  - Los países `29`, `57`, `34`, y `25` representan la totalidad de la muestra.\n",
    "  - El valor imputado (probablemente uno de estos países) se integra bien en la distribución global.\n",
    "\n",
    "**Conclusión**: La imputación en `country` fue exitosa y no distorsiona la representación de los datos.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. División en conjuntos de entrenamiento y validación**\n",
    "- **Tamaño del entrenamiento**: **294,871 filas** (80% de la muestra).\n",
    "- **Tamaño de la validación**: **73,718 filas** (20% de la muestra).\n",
    "- **Implicaciones**:\n",
    "  - La división parece adecuada para experimentos iniciales, dejando un conjunto representativo para evaluar el rendimiento del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistimos los datasets (Back_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los datasets han sido guardados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Definir rutas para guardar los datasets\n",
    "train_path = \"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/hybrid_model/train_preprocessed.pkl\"\n",
    "test_path = \"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/hybrid_model/test_preprocessed.pkl\"\n",
    "sample_path = \"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/hybrid_model/train_sample_preprocessed.pkl\"\n",
    "train_set_path = \"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/hybrid_model/train_set.pkl\"\n",
    "val_set_path = \"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/hybrid_model/val_set.pkl\"\n",
    "\n",
    "# Guardar los datasets\n",
    "train.to_pickle(train_path)\n",
    "test.to_pickle(test_path)\n",
    "train_sample.to_pickle(sample_path)\n",
    "train_set.to_pickle(train_set_path)\n",
    "val_set.to_pickle(val_set_path)\n",
    "\n",
    "print(\"Todos los datasets han sido guardados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
