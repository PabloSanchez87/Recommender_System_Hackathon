{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pipeline para usuarios no logueados**\n",
    "\n",
    "1. **Cargar y procesar el dataset de prueba**:\n",
    "   - Identificar sesiones donde `user_id = -1`.\n",
    "\n",
    "2. **Generar recomendaciones**:\n",
    "   - Basado en popularidad global (familias y colores más populares).\n",
    "   - Ajustar por atributos contextuales (`pagetype`, `device_type`).\n",
    "\n",
    "3. **Formato de predicciones**:\n",
    "   - Generar el archivo JSON con 5 recomendaciones únicas por `session_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones para usuarios no logueados guardadas en /home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_unlogged.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cargar datasets de prueba y productos\n",
    "test_df = pd.read_pickle(\"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/test_data.pkl\")\n",
    "products_df = pd.read_pickle(\"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/products_data_enriched.pkl\")\n",
    "\n",
    "# Familias y colores más populares (globales)\n",
    "popular_families = products_df['family'].value_counts().index.tolist()\n",
    "popular_colors = products_df['color_id'].value_counts().index.tolist()\n",
    "\n",
    "# Filtrar valores negativos en 'partnumber'\n",
    "products_df = products_df[products_df['partnumber'] > 0]\n",
    "\n",
    "# Generar recomendaciones para usuarios no logueados\n",
    "def generate_unlogged_recommendations(test_df, products_df):\n",
    "    \"\"\"Genera recomendaciones para usuarios no logueados en el formato correcto.\"\"\"\n",
    "    predictions = {}\n",
    "    unlogged_sessions = test_df[test_df['user_id'] == -1]\n",
    "\n",
    "    for session_id in unlogged_sessions['session_id'].unique():\n",
    "        # Selección de productos (basado en popularidad)\n",
    "        recommended_products = products_df[\n",
    "            (products_df['family'].isin(popular_families)) &\n",
    "            (products_df['color_id'].isin(popular_colors))\n",
    "        ]['partnumber'].drop_duplicates().head(5).tolist()\n",
    "\n",
    "        # Asegurar valores positivos y agregar al diccionario de predicciones\n",
    "        predictions[str(session_id)] = [int(product) for product in recommended_products]\n",
    "\n",
    "    return {\"target\": predictions}\n",
    "\n",
    "# Generar predicciones\n",
    "unlogged_predictions = generate_unlogged_recommendations(test_df, products_df)\n",
    "\n",
    "# Guardar predicciones en formato JSON\n",
    "output_path = \"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_unlogged.json\"\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(unlogged_predictions, f, indent=4)\n",
    "\n",
    "print(f\"Predicciones para usuarios no logueados guardadas en {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en 'partnumber':\n",
      "partnumber\n",
      "-32760    1\n",
      " 25473    1\n",
      " 28822    1\n",
      " 25251    1\n",
      " 25252    1\n",
      "         ..\n",
      " 14798    1\n",
      " 16734    1\n",
      " 19097    1\n",
      " 16511    1\n",
      " 238      1\n",
      "Name: count, Length: 43692, dtype: int64\n",
      "\n",
      "Cantidad de valores '-1' en 'partnumber': 0\n"
     ]
    }
   ],
   "source": [
    "# Inspeccionar valores únicos en 'partnumber'\n",
    "print(\"Valores únicos en 'partnumber':\")\n",
    "print(products_df['partnumber'].value_counts())\n",
    "\n",
    "# Verificar la frecuencia de -1\n",
    "null_partnumber_count = (products_df['partnumber'] == -1).sum()\n",
    "print(f\"\\nCantidad de valores '-1' en 'partnumber': {null_partnumber_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones diversificadas para usuarios no logueados guardadas en /home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_unlogged_random.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generar recomendaciones para usuarios no logueados\n",
    "def generate_unlogged_recommendations(test_df, products_df):\n",
    "    \"\"\"Genera recomendaciones diversificadas para usuarios no logueados en el formato correcto.\"\"\"\n",
    "    predictions = {}\n",
    "    unlogged_sessions = test_df[test_df['user_id'] == -1]\n",
    "\n",
    "    # Lista de productos más populares\n",
    "    popular_products = products_df[\n",
    "        (products_df['family'].isin(popular_families)) &\n",
    "        (products_df['color_id'].isin(popular_colors))\n",
    "    ]['partnumber'].drop_duplicates().tolist()\n",
    "\n",
    "    for session_id in unlogged_sessions['session_id'].unique():\n",
    "        # Selección aleatoria de 5 productos populares\n",
    "        recommended_products = np.random.choice(popular_products, 5, replace=False).tolist()\n",
    "\n",
    "        # Agregar al diccionario de predicciones\n",
    "        predictions[str(session_id)] = recommended_products\n",
    "\n",
    "    return {\"target\": predictions}\n",
    "\n",
    "# Generar predicciones\n",
    "unlogged_predictions = generate_unlogged_recommendations(test_df, products_df)\n",
    "\n",
    "# Guardar predicciones en formato JSON\n",
    "output_path = \"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_unlogged_random.json\"\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(unlogged_predictions, f, indent=4)\n",
    "\n",
    "print(f\"Predicciones diversificadas para usuarios no logueados guardadas en {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pipeline para usuarios logueados**\n",
    "\n",
    "#### **Estrategia**\n",
    "1. **Basado en historial**:\n",
    "   - Utilizar las interacciones previas de cada usuario para generar recomendaciones personalizadas.\n",
    "   - Usar atributos como `family`, `color_id`, y `similar_products` para recomendaciones basadas en contenido.\n",
    "\n",
    "2. **Segmentación dinámica**:\n",
    "   - Incorporar características como `RFM_score` y `user_class` para ajustar las recomendaciones.\n",
    "\n",
    "3. **Modelo híbrido**:\n",
    "   - Combinar enfoques colaborativos (similitud entre usuarios) y basados en contenido (atributos de productos).\n",
    "\n",
    "### **Plan de acción**\n",
    "\n",
    "1. **Preparar el historial de interacciones**:\n",
    "   - Identificar los productos con los que cada usuario ha interactuado en el conjunto de entrenamiento.\n",
    "\n",
    "2. **Entrenar un modelo colaborativo**:\n",
    "   - Usar las interacciones previas para entrenar un modelo como `ALS` (Alternating Least Squares) o un modelo de factorización matricial.\n",
    "\n",
    "3. **Incorporar atributos de contenido**:\n",
    "   - Combinar atributos de usuario (`RFM_score`, `user_class`) y producto (`family`, `color_id`, `cluster`) para generar recomendaciones.\n",
    "\n",
    "4. **Formato de salida**:\n",
    "   - Generar un archivo JSON con las recomendaciones personalizadas para cada `session_id`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones para usuarios logueados guardadas en /home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_logged.json\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cargar datasets\n",
    "train_df = pd.read_pickle(\"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/train_data_enriched.pkl\")\n",
    "test_df = pd.read_pickle(\"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/test_data.pkl\")\n",
    "products_df = pd.read_pickle(\"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/products_data_enriched.pkl\")\n",
    "\n",
    "# 1. Preparar datos para el modelo colaborativo\n",
    "interactions = train_df[['user_id', 'partnumber', 'session_id']].copy()\n",
    "interactions['rating'] = 1  # Asignar valor ficticio para indicar interacción\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(interactions[['user_id', 'partnumber', 'rating']], reader)\n",
    "\n",
    "# Entrenar modelo colaborativo\n",
    "trainset = data.build_full_trainset()\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Filtrar valores negativos en 'partnumber'\n",
    "products_df = products_df[products_df['partnumber'] > 0]\n",
    "\n",
    "\n",
    "# Generar recomendaciones personalizadas para usuarios logueados\n",
    "def generate_logged_recommendations(test_df, products_df, train_df, model):\n",
    "    \"\"\"Genera recomendaciones más personalizadas para usuarios logueados.\"\"\"\n",
    "    predictions = {}\n",
    "    logged_sessions = test_df[test_df['user_id'] != -1]\n",
    "\n",
    "    for _, row in logged_sessions.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        session_id = row['session_id']\n",
    "\n",
    "        # Obtener productos vistos por el usuario\n",
    "        seen_products = train_df[train_df['user_id'] == user_id]['partnumber'].unique()\n",
    "\n",
    "        # Filtrar productos no vistos\n",
    "        unseen_products = products_df[~products_df['partnumber'].isin(seen_products)]['partnumber'].tolist()\n",
    "\n",
    "        # Generar predicciones personalizadas\n",
    "        recommended_products = []\n",
    "        for product in unseen_products:\n",
    "            pred = model.predict(user_id, product).est\n",
    "            recommended_products.append((product, pred))\n",
    "\n",
    "        # Ordenar por predicción y diversificar\n",
    "        recommended_products = [int(p[0]) for p in sorted(recommended_products, key=lambda x: x[1], reverse=True)[:5]]\n",
    "\n",
    "        # Agregar recomendaciones al diccionario\n",
    "        predictions[str(session_id)] = recommended_products\n",
    "\n",
    "    return {\"target\": predictions}\n",
    "\n",
    "# Generar y guardar predicciones\n",
    "logged_predictions = generate_logged_recommendations(test_df, products_df, train_df, model)\n",
    "\n",
    "output_path = \"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_logged.json\"\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(logged_predictions, f, indent=4)\n",
    "\n",
    "print(f\"Predicciones para usuarios logueados guardadas en {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinar json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo JSON final generado: /home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_final.json\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Rutas de los archivos\n",
    "path_unlogged = \"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_unlogged.json\"\n",
    "path_logged = \"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_logged.json\"\n",
    "path_test_data = \"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/test_data.pkl\"\n",
    "output_path = \"/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_final.json\"\n",
    "\n",
    "# Cargar archivos JSON existentes\n",
    "with open(path_unlogged, 'r') as f:\n",
    "    unlogged_predictions = json.load(f)[\"target\"]\n",
    "\n",
    "with open(path_logged, 'r') as f:\n",
    "    logged_predictions = json.load(f)[\"target\"]\n",
    "\n",
    "# Cargar el dataset de prueba para obtener todos los session_id\n",
    "test_df = pd.read_pickle(path_test_data)\n",
    "all_session_ids = test_df['session_id'].unique()\n",
    "\n",
    "# Combinar predicciones\n",
    "final_predictions = {}\n",
    "for session_id in all_session_ids:\n",
    "    session_id_str = str(session_id)\n",
    "\n",
    "    if session_id_str in logged_predictions:\n",
    "        final_predictions[session_id_str] = logged_predictions[session_id_str]\n",
    "    elif session_id_str in unlogged_predictions:\n",
    "        final_predictions[session_id_str] = unlogged_predictions[session_id_str]\n",
    "    else:\n",
    "        # Si falta, llenar con productos más populares globalmente\n",
    "        final_predictions[session_id_str] = [13211, 21402, 14933, 12765, 13402]  # Ejemplo\n",
    "\n",
    "# Guardar el archivo final\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump({\"target\": final_predictions}, f, indent=4)\n",
    "\n",
    "print(f\"Archivo JSON final generado: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
