{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cargando datos de entrenamiento ---\n",
      "\n",
      "--- Preprocesando y enriqueciendo datos (train) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1289/3834726871.py:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['day_period_popularity'] = df.groupby('hour_bucket')['partnumber'].transform('count')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Entrenando modelo Lambdamart ---\n",
      "Modelo guardado en /home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/models/lambdamart_model.txt\n",
      "\n",
      "--- Cargando el modelo entrenado ---\n",
      "\n",
      "--- Cargando datos de prueba ---\n",
      "\n",
      "--- Preprocesando y enriqueciendo datos (test) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1289/3834726871.py:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['day_period_popularity'] = df.groupby('hour_bucket')['partnumber'].transform('count')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generando predicciones ---\n",
      "\n",
      "--- Guardando predicciones ---\n",
      "Predicciones guardadas en /home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_lambda_v1.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Preprocesamiento y enriquecimiento ---\n",
    "def preprocess_and_enrich_data(df, mode='train'):\n",
    "    print(f\"\\n--- Preprocesando y enriqueciendo datos ({mode}) ---\")\n",
    "    df['date'] = pd.to_datetime(df['date']).astype(int) / 10**9\n",
    "    df['timestamp_local'] = pd.to_datetime(df['timestamp_local']).astype(int) / 10**9\n",
    "    df['hour'] = pd.to_datetime(df['timestamp_local'], unit='s').dt.hour\n",
    "    df['day_of_week'] = pd.to_datetime(df['timestamp_local'], unit='s').dt.dayofweek\n",
    "\n",
    "    session_length = df.groupby('session_id')['partnumber'].transform('count')\n",
    "    df['session_length'] = session_length\n",
    "    df['country_popularity'] = df.groupby('country')['partnumber'].transform('count') / session_length\n",
    "    df['product_interaction_rate'] = df.groupby('partnumber')['session_id'].transform('nunique') / session_length\n",
    "\n",
    "    # Características adicionales\n",
    "    df['hour_bucket'] = pd.cut(\n",
    "        df['hour'], \n",
    "        bins=[0, 6, 12, 18, 24], \n",
    "        labels=['Noche1', 'Mañana', 'Tarde', 'Noche2'],  # Etiquetas únicas\n",
    "        include_lowest=True\n",
    "    )\n",
    "    df['day_period_popularity'] = df.groupby('hour_bucket')['partnumber'].transform('count')\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Entrenamiento del modelo ---\n",
    "def train_lambdamart(train_path, model_path):\n",
    "    print(\"\\n--- Cargando datos de entrenamiento ---\")\n",
    "    train_df = pd.read_pickle(train_path)\n",
    "    train_df = preprocess_and_enrich_data(train_df)\n",
    "\n",
    "    # Dividir características y etiquetas\n",
    "    X = train_df.drop(['add_to_cart', 'session_id'], axis=1)\n",
    "    y = train_df['add_to_cart']\n",
    "    groups = train_df['session_id'].value_counts().values\n",
    "\n",
    "    # Crear Dataset LightGBM\n",
    "    train_data = lgb.Dataset(X, label=y, group=groups)\n",
    "\n",
    "    # Parámetros del modelo\n",
    "    params = {\n",
    "        'objective': 'lambdarank',\n",
    "        'metric': 'ndcg',\n",
    "        'ndcg_eval_at': [1, 3, 5],\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 70,\n",
    "        'max_bin': 255,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    # Entrenar modelo\n",
    "    print(\"\\n--- Entrenando modelo Lambdamart ---\")\n",
    "    model = lgb.train(\n",
    "        params, train_data,\n",
    "        num_boost_round=500,\n",
    "        valid_sets=[train_data],\n",
    "        valid_names=['train'],\n",
    "    )\n",
    "\n",
    "    # Guardar modelo\n",
    "    model.save_model(model_path)\n",
    "    print(f\"Modelo guardado en {model_path}\")\n",
    "\n",
    "def generate_predictions(model_path, test_path, output_path):\n",
    "    print(\"\\n--- Cargando el modelo entrenado ---\")\n",
    "    model = lgb.Booster(model_file=model_path)\n",
    "\n",
    "    print(\"\\n--- Cargando datos de prueba ---\")\n",
    "    test_df = pd.read_pickle(test_path)\n",
    "    test_df = preprocess_and_enrich_data(test_df, mode='test')\n",
    "\n",
    "    session_ids = test_df['session_id'].unique()\n",
    "    predictions = {}\n",
    "    popular_products = test_df['partnumber'].value_counts().index.tolist()\n",
    "\n",
    "    print(\"\\n--- Generando predicciones ---\")\n",
    "    for session_id in session_ids:\n",
    "        session_data = test_df[test_df['session_id'] == session_id].copy()\n",
    "\n",
    "        if session_data.empty:\n",
    "            predictions[str(session_id)] = popular_products[:5]\n",
    "            continue\n",
    "\n",
    "        session_features = session_data.drop(['session_id'], axis=1)\n",
    "        session_data['score'] = model.predict(session_features)\n",
    "\n",
    "        recommended_products = (\n",
    "            session_data.sort_values(by='score', ascending=False)['partnumber']\n",
    "            .drop_duplicates()\n",
    "            .tolist()\n",
    "        )\n",
    "\n",
    "        # Completar recomendaciones con productos populares sin duplicados\n",
    "        unique_recommended_products = set(recommended_products)\n",
    "        for product in popular_products:\n",
    "            if len(recommended_products) >= 5:\n",
    "                break\n",
    "            if product not in unique_recommended_products:\n",
    "                recommended_products.append(product)\n",
    "                unique_recommended_products.add(product)\n",
    "\n",
    "        predictions[str(session_id)] = recommended_products[:5]\n",
    "\n",
    "    print(\"\\n--- Guardando predicciones ---\")\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump({\"target\": predictions}, f, indent=4)\n",
    "    print(f\"Predicciones guardadas en {output_path}\")\n",
    "\n",
    "\n",
    "# --- Ejecutar ---\n",
    "if __name__ == \"__main__\":\n",
    "    train_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/train_data.pkl'\n",
    "    test_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/test_data.pkl'\n",
    "    model_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/models/lambdamart_model.txt'\n",
    "    output_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_lambda_v1.json'\n",
    "\n",
    "    train_lambdamart(train_path, model_path)\n",
    "    generate_predictions(model_path, test_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cargando el modelo entrenado ---\n",
      "\n",
      "--- Cargando datos de prueba ---\n",
      "\n",
      "--- Preprocesando y enriqueciendo datos (test) ---\n",
      "\n",
      "--- Generando predicciones ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1366/271695325.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['day_period_popularity'] = df.groupby('hour_bucket')['partnumber'].transform('count')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Guardando predicciones ---\n",
      "Predicciones guardadas en /home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_lambda_v1.json\n"
     ]
    }
   ],
   "source": [
    "# --- Preprocesamiento y enriquecimiento ---\n",
    "def preprocess_and_enrich_data(df, mode='train'):\n",
    "    print(f\"\\n--- Preprocesando y enriqueciendo datos ({mode}) ---\")\n",
    "    df['date'] = pd.to_datetime(df['date']).astype(int) / 10**9\n",
    "    df['timestamp_local'] = pd.to_datetime(df['timestamp_local']).astype(int) / 10**9\n",
    "    df['hour'] = pd.to_datetime(df['timestamp_local'], unit='s').dt.hour\n",
    "    df['day_of_week'] = pd.to_datetime(df['timestamp_local'], unit='s').dt.dayofweek\n",
    "\n",
    "    session_length = df.groupby('session_id')['partnumber'].transform('count')\n",
    "    df['session_length'] = session_length\n",
    "    df['country_popularity'] = df.groupby('country')['partnumber'].transform('count') / session_length\n",
    "    df['product_interaction_rate'] = df.groupby('partnumber')['session_id'].transform('nunique') / session_length\n",
    "\n",
    "    # Características adicionales\n",
    "    df['hour_bucket'] = pd.cut(\n",
    "        df['hour'], \n",
    "        bins=[0, 6, 12, 18, 24], \n",
    "        labels=['Noche1', 'Mañana', 'Tarde', 'Noche2'],  # Etiquetas únicas\n",
    "        include_lowest=True\n",
    "    )\n",
    "    df['day_period_popularity'] = df.groupby('hour_bucket')['partnumber'].transform('count')\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_predictions(model_path, test_path, output_path):\n",
    "    print(\"\\n--- Cargando el modelo entrenado ---\")\n",
    "    model = lgb.Booster(model_file=model_path)\n",
    "\n",
    "    print(\"\\n--- Cargando datos de prueba ---\")\n",
    "    test_df = pd.read_pickle(test_path)\n",
    "    test_df = preprocess_and_enrich_data(test_df, mode='test')\n",
    "\n",
    "    session_ids = test_df['session_id'].unique()\n",
    "    predictions = {}\n",
    "    popular_products = test_df['partnumber'].value_counts().index.tolist()\n",
    "\n",
    "    print(\"\\n--- Generando predicciones ---\")\n",
    "    for session_id in session_ids:\n",
    "        session_data = test_df[test_df['session_id'] == session_id].copy()\n",
    "\n",
    "        if session_data.empty:\n",
    "            predictions[str(session_id)] = popular_products[:5]\n",
    "            continue\n",
    "\n",
    "        session_features = session_data.drop(['session_id'], axis=1)\n",
    "        session_data['score'] = model.predict(session_features)\n",
    "\n",
    "        recommended_products = (\n",
    "            session_data.sort_values(by='score', ascending=False)['partnumber']\n",
    "            .drop_duplicates()\n",
    "            .tolist()\n",
    "        )\n",
    "\n",
    "        # Completar recomendaciones con productos populares sin duplicados\n",
    "        unique_recommended_products = set(recommended_products)\n",
    "        for product in popular_products:\n",
    "            if len(recommended_products) >= 5:\n",
    "                break\n",
    "            if product not in unique_recommended_products:\n",
    "                recommended_products.append(product)\n",
    "                unique_recommended_products.add(product)\n",
    "\n",
    "        predictions[str(session_id)] = recommended_products[:5]\n",
    "\n",
    "    print(\"\\n--- Guardando predicciones ---\")\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump({\"target\": predictions}, f, indent=4)\n",
    "    print(f\"Predicciones guardadas en {output_path}\")\n",
    "    \n",
    "train_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/train_data.pkl'\n",
    "test_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/test_data.pkl'\n",
    "model_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/models/lambdamart_model.txt'\n",
    "output_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_lambda_v1.json'\n",
    "\n",
    "generate_predictions(model_path, test_path, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
