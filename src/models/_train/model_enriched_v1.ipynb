{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis y Consideraciones\n",
    "1. **Características Enriquecidas en el Train**: \n",
    "   - Nuevas columnas como `session_interactions`, `discount_category`, `similar_products`, `popularity`, `cluster`, etc., ofrecen una riqueza de información sobre el comportamiento de los usuarios y los productos.\n",
    "   - Sin embargo, muchas de estas características no están presentes en el dataset de prueba (`test_data`). Por ejemplo, `add_to_cart`, `session_interactions`, `discount_category`, y `similar_products` no aparecen en `test`.\n",
    "\n",
    "2. **Dataset de Prueba**:\n",
    "   - Contiene columnas básicas (`session_id`, `date`, `timestamp_local`, `user_id`, `country`, `partnumber`, `device_type`, `pagetype`).\n",
    "   - Por lo tanto, el modelo debe ser diseñado para funcionar únicamente con las características que también están disponibles en el dataset de prueba.\n",
    "\n",
    "3. **Aprovechar el Dataset Enriquecido**:\n",
    "   - Utilizar las características enriquecidas para crear interacciones más complejas en el entrenamiento.\n",
    "   - Generar características derivadas basadas en patrones que puedan ser representadas con las columnas del dataset de prueba.\n",
    "\n",
    "4. **Objetivo**:\n",
    "   - Diseñar un modelo (como LambdaMART) que utilice características compartidas entre `train` y `test`.\n",
    "   - Introducir transformaciones o modelos adicionales que puedan inferir las características ausentes en el dataset de prueba (por ejemplo, estimar la `popularidad` de productos en base a patrones previos).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Estrategia Propuesta\n",
    "#### 1. **Selección de Características**\n",
    "   - Seleccionar solo las características comunes entre `train` y `test`:\n",
    "     - `session_id`, `date`, `timestamp_local`, `user_id`, `country`, `partnumber`, `device_type`, `pagetype`.\n",
    "   - Generar características adicionales que puedan calcularse tanto en `train` como en `test`, como:\n",
    "     - **Interacciones por sesión** (`session_length`).\n",
    "     - **Popularidad relativa del producto** (`product_popularity`).\n",
    "     - **Hora y día de interacción** (`hour`, `day_of_week`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_generate_shared_features(df, mode=\"train\"):\n",
    "    print(f\"\\n--- Preprocesando y generando características compartidas ({mode}) ---\")\n",
    "\n",
    "    # Convertir datetime a numérico (segundos desde el epoch)\n",
    "    if \"date\" in df.columns:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"]).astype(int) / 10**9\n",
    "    if \"timestamp_local\" in df.columns:\n",
    "        df[\"timestamp_local\"] = pd.to_datetime(df[\"timestamp_local\"]).astype(int) / 10**9\n",
    "\n",
    "    # Generar características compartidas\n",
    "    if \"partnumber\" in df.columns:\n",
    "        df[\"product_popularity\"] = df.groupby(\"partnumber\")[\"session_id\"].transform(\"nunique\")\n",
    "    if \"session_id\" in df.columns:\n",
    "        df[\"session_length\"] = df.groupby(\"session_id\")[\"partnumber\"].transform(\"count\")\n",
    "\n",
    "    # Codificar `discount_category` como numérico\n",
    "    if \"discount_category\" in df.columns:\n",
    "        df[\"discount_category\"] = df[\"discount_category\"].astype(\"category\").cat.codes\n",
    "\n",
    "    # Procesar `similar_products` como longitud de lista\n",
    "    if \"similar_products\" in df.columns:\n",
    "        df[\"similar_products_count\"] = df[\"similar_products\"].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "        df.drop(columns=[\"similar_products\"], inplace=True)\n",
    "\n",
    "    # Manejar columnas no compatibles en modo `test`\n",
    "    if mode == \"test\":\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype not in [np.int32, np.int64, np.float32, np.float64, np.bool_]:\n",
    "                print(f\"Eliminando columna no compatible: {col}\")\n",
    "                df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_global_stats(train_df):\n",
    "    print(\"\\n--- Generando estadísticas globales del entrenamiento ---\")\n",
    "    stats = {}\n",
    "    stats['product_popularity'] = train_df.groupby('partnumber')['session_id'].nunique()\n",
    "    stats['discount_category'] = train_df['discount_category'].value_counts(normalize=True).to_dict()\n",
    "    stats['cluster'] = train_df['cluster'].value_counts(normalize=True).to_dict()\n",
    "\n",
    "    # Asignar valores por defecto para test\n",
    "    stats['discount_category']['default'] = max(stats['discount_category'], key=stats['discount_category'].get)\n",
    "    stats['cluster']['default'] = max(stats['cluster'], key=stats['cluster'].get)\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test_with_enrichment(test_df, global_stats, train_features):\n",
    "    print(\"\\n--- Preprocesando conjunto de prueba con enriquecimiento ---\")\n",
    "\n",
    "    if 'session_id' not in test_df.columns:\n",
    "        raise KeyError(\"El conjunto de prueba no contiene 'session_id' al inicio.\")\n",
    "\n",
    "    # Convertir columnas datetime a numérico\n",
    "    test_df['date'] = pd.to_datetime(test_df['date']).astype(int) / 10**9\n",
    "    test_df['timestamp_local'] = pd.to_datetime(test_df['timestamp_local']).astype(int) / 10**9\n",
    "    test_df['hour'] = pd.to_datetime(test_df['timestamp_local'], unit='s').dt.hour\n",
    "    test_df['day_of_week'] = pd.to_datetime(test_df['timestamp_local'], unit='s').dt.dayofweek\n",
    "\n",
    "    # Generar características derivadas\n",
    "    test_df['session_length'] = test_df.groupby('session_id')['partnumber'].transform('count')\n",
    "    test_df['product_popularity'] = global_stats['product_popularity'].reindex(test_df['partnumber']).fillna(0).astype(float).values\n",
    "\n",
    "    # Manejar columna `discount_category`\n",
    "    if 'discount_category' not in test_df.columns:\n",
    "        test_df['discount_category'] = global_stats['discount_category']['default']\n",
    "    else:\n",
    "        test_df['discount_category'] = (\n",
    "            test_df['discount_category']\n",
    "            .map(global_stats['discount_category'])\n",
    "            .fillna(global_stats['discount_category']['default'])\n",
    "        ).astype(int)\n",
    "\n",
    "    # Manejar otras columnas faltantes o imputadas\n",
    "    if 'similar_products_count' not in test_df.columns:\n",
    "        test_df['similar_products_count'] = 0\n",
    "    if 'cluster' not in test_df.columns:\n",
    "        test_df['cluster'] = global_stats['cluster']['default']\n",
    "\n",
    "    # Agregar columnas faltantes\n",
    "    for feature in train_features:\n",
    "        if feature not in test_df.columns:\n",
    "            print(f\"Agregando columna faltante: {feature}\")\n",
    "            test_df[feature] = 0\n",
    "\n",
    "    # Convertir todas las columnas a tipos compatibles\n",
    "    for col in test_df.columns:\n",
    "        if col not in train_features + ['session_id']:\n",
    "            continue\n",
    "        if test_df[col].dtype == 'int64':\n",
    "            test_df[col] = test_df[col].astype(np.int32)\n",
    "        elif test_df[col].dtype == 'float64':\n",
    "            test_df[col] = test_df[col].astype(np.float32)\n",
    "\n",
    "    # Verificar que todas las columnas en `train_features` están presentes y tienen tipos válidos\n",
    "    missing_features = [f for f in train_features if f not in test_df.columns]\n",
    "    if missing_features:\n",
    "        raise ValueError(f\"Faltan características en el conjunto de prueba: {missing_features}\")\n",
    "\n",
    "    # Validar tipos finales\n",
    "    invalid_dtypes = test_df.dtypes[~test_df.dtypes.isin([np.int32, np.float32, np.bool_])]\n",
    "    if not invalid_dtypes.empty:\n",
    "        raise ValueError(f\"Columnas con tipos de datos no válidos: {invalid_dtypes}\")\n",
    "\n",
    "    return test_df[['session_id'] + train_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. **Entrenamiento con LambdaMART**\n",
    "   - Utilizar las características generadas anteriormente para entrenar el modelo.\n",
    "   - Excluir características no disponibles en `test` durante el entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lambdamart_with_enrichment(train_path, model_path):\n",
    "    print(\"\\n--- Cargando datos de entrenamiento enriquecidos ---\")\n",
    "    train_df = pd.read_pickle(train_path)\n",
    "    train_df = preprocess_and_generate_shared_features(train_df, mode=\"train\")\n",
    "    if \"add_to_cart\" not in train_df.columns:\n",
    "        raise ValueError(\"La columna 'add_to_cart' no está presente en el conjunto de datos.\")\n",
    "\n",
    "    X = train_df.drop(['add_to_cart', 'session_id'], axis=1)\n",
    "    y = train_df['add_to_cart']\n",
    "    groups = train_df['session_id'].value_counts().values\n",
    "\n",
    "    lgb_train = lgb.Dataset(X, label=y, group=groups)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'lambdarank',\n",
    "        'metric': 'ndcg',\n",
    "        'ndcg_eval_at': [1, 3, 5],\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 70,\n",
    "        'max_bin': 255,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    model = lgb.train(\n",
    "        params, lgb_train,\n",
    "        num_boost_round=500,\n",
    "        valid_sets=[lgb_train],\n",
    "        valid_names=['train']\n",
    "    )\n",
    "\n",
    "    model.save_model(model_path)\n",
    "    return X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. **Generación de Predicciones**\n",
    "   - Utilizar el mismo conjunto de características para generar predicciones.\n",
    "   - Aplicar el modelo entrenado al conjunto de prueba `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_with_enrichment(model_path, test_path, output_path, global_stats, train_features):\n",
    "    print(\"\\n--- Cargando el modelo entrenado ---\")\n",
    "    model = lgb.Booster(model_file=model_path)\n",
    "    test_df = pd.read_pickle(test_path)\n",
    "    test_df = preprocess_test_with_enrichment(test_df, global_stats, train_features)\n",
    "\n",
    "    predictions = {}\n",
    "    popular_products = test_df['partnumber'].value_counts().index.tolist()\n",
    "\n",
    "    print(\"\\n--- Generando predicciones para cada sesión ---\")\n",
    "    for session_id in test_df['session_id'].unique():\n",
    "        session_data = test_df[test_df['session_id'] == session_id].copy()\n",
    "        if session_data.empty:\n",
    "            predictions[str(session_id)] = popular_products[:5]\n",
    "            continue\n",
    "\n",
    "        session_features = session_data[train_features]\n",
    "        session_data['score'] = model.predict(session_features)\n",
    "\n",
    "        recommended_products = (\n",
    "            session_data.sort_values(by='score', ascending=False)['partnumber']\n",
    "            .drop_duplicates()\n",
    "            .tolist()\n",
    "        )\n",
    "\n",
    "        for product in popular_products:\n",
    "            if len(recommended_products) >= 5:\n",
    "                break\n",
    "            if product not in recommended_products:\n",
    "                recommended_products.append(product)\n",
    "\n",
    "        predictions[str(session_id)] = recommended_products[:5]\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump({\"target\": predictions}, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "#### **1. Preprocesamiento y Generación de Características Compartidas**\n",
    "- **Función: `preprocess_and_generate_shared_features`**\n",
    "    - **Pros:**\n",
    "        - Convierte fechas a numéricos.\n",
    "        - Genera características clave como `product_popularity` y `session_length`.\n",
    "        - Maneja columnas faltantes asignando valores predeterminados.\n",
    "        - Elimina columnas con tipos de datos incompatibles.\n",
    "    - **Preguntas clave:**\n",
    "        - ¿Está `hour` siendo generada en algún paso previo en el `test`? Si no, necesitarías agregar ese cálculo aquí.\n",
    "        - Si se espera agregar características personalizadas (como promedios de `discount_category` o `cluster`), ¿deberían incluirse aquí o en una etapa posterior?\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Generar Estadísticas Globales**\n",
    "- **Función: `generate_global_stats`**\n",
    "    - **Pros:**\n",
    "        - Calcula estadísticas globales útiles como la popularidad de productos y la distribución de categorías.\n",
    "        - Asigna valores predeterminados para características faltantes en el conjunto de prueba.\n",
    "    - **Revisión:**\n",
    "        - Las estadísticas generadas son adecuadas para imputar valores en el conjunto de prueba.\n",
    "        - Asegúrate de que las claves y valores sean consistentes entre `train` y `test` (por ejemplo, `discount_category` podría no existir en `test`).\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Preprocesamiento del Conjunto de Prueba**\n",
    "- **Función: `preprocess_test_with_enrichment`**\n",
    "    - **Pros:**\n",
    "        - Imputa características faltantes usando las estadísticas globales.\n",
    "        - Genera características derivadas como `session_length` y `product_popularity`.\n",
    "    - **Preguntas clave:**\n",
    "        - ¿Es `similar_products_count` una característica relevante? Si no, podría omitirse para simplificar.\n",
    "        - Validar que las columnas generadas coincidan exactamente con las del `train` después del preprocesamiento.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Entrenamiento del Modelo**\n",
    "- **Función: `train_lambdamart_with_enrichment`**\n",
    "    - **Pros:**\n",
    "        - Usa las características enriquecidas del conjunto de entrenamiento.\n",
    "        - Configura el modelo Lambdamart con parámetros estándar de `LightGBM`.\n",
    "    - **Preguntas clave:**\n",
    "        - ¿Se ha probado la robustez del modelo al eliminar características no compartidas del `train`? Esto asegura que el modelo no dependa de datos que no estarán disponibles en el `test`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Generación de Predicciones**\n",
    "- **Función: `generate_predictions_with_enrichment`**\n",
    "    - **Pros:**\n",
    "        - Garantiza que cada `session_id` tenga exactamente 5 productos únicos.\n",
    "        - Usa características derivadas e imputadas en el `test`.\n",
    "    - **Revisión:**\n",
    "        - Validar que los productos recomendados no incluyan duplicados y estén ordenados por puntuación predicha.\n",
    "        - Asegurar que las características usadas para predecir sean exactamente las mismas que durante el entrenamiento.\n",
    "\n",
    "---\n",
    "\n",
    "### **Resumen**\n",
    "\n",
    "El pipeline es sólido y completo, pero aquí hay algunos puntos clave a revisar:\n",
    "1. **Validación de Columnas Compartidas:**\n",
    "    - Garantizar que las columnas generadas en `test` coincidan exactamente con las del `train` después del preprocesamiento.\n",
    "    - Eliminar cualquier columna irrelevante o no compatible antes de alimentar el modelo.\n",
    "\n",
    "2. **Manejo de Datos Faltantes:**\n",
    "    - Las estadísticas globales son esenciales para rellenar datos faltantes en `test`.\n",
    "    - Validar que las imputaciones no introduzcan sesgos significativos.\n",
    "\n",
    "3. **Predicciones:**\n",
    "    - Garantizar que las predicciones generen 5 productos únicos por sesión.\n",
    "    - Asegurar que los productos más populares sean usados como respaldo para sesiones con datos insuficientes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Generar las Estadísticas Globales**\n",
    "Ejecuta el siguiente código para calcular las estadísticas globales basadas en el conjunto de entrenamiento enriquecido:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/train_data_final.pkl'\n",
    "\n",
    "# Cargar datos de entrenamiento\n",
    "train_df = pd.read_pickle(train_path)\n",
    "\n",
    "# Generar estadísticas globales\n",
    "global_stats = generate_global_stats(train_df)\n",
    "# print(global_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Entrenar el Modelo**\n",
    "Entrena el modelo Lambdamart usando las características enriquecidas del conjunto de entrenamiento:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/models/lambdamart_enriched_shared_model.txt'\n",
    "\n",
    "# Entrenar modelo y obtener características de entrenamiento\n",
    "train_features = train_lambdamart_with_enrichment(train_path, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Generar las Predicciones**\n",
    "Usa el modelo entrenado para generar predicciones basadas en el conjunto de prueba y las estadísticas globales:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/data/processed/new_processed/test_data.pkl'\n",
    "output_path = '/home/pablost/Hackathon_inditex_data_science/hackathon-inditex-data-recommender/predictions/predictions_3_shared.json'\n",
    "\n",
    "# Generar predicciones\n",
    "generate_predictions_with_enrichment(model_path, test_path, output_path, global_stats, train_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Validar el JSON**\n",
    "Valida que el JSON generado cumpla con el formato requerido:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Validar formato del JSON\n",
    "with open(output_path, 'r') as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "# Mostrar una parte del JSON para verificación\n",
    "print(\"\\n--- Validación del JSON generado ---\")\n",
    "print(json.dumps(predictions, indent=4)[:1000])  # Mostrar los primeros 1000 caracteres\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
